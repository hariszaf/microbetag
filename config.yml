#
# microbetag parameters
#

# Run as a container - if True then the IO path will be /mnt. If false please provide the input - output path 
approach: 
  container: False
  io_path: /tests/ # if docker : null

# OUTPUT
# ------
output_directory: output_dev_qiime2 # output_dev_qiime2

# OTU TABLE
# ----------

# Filename of your OTU table
otu_table: qiime2_use_case.tsv   # otu_table_silva132_partial.tsv   #  table.from_biom_w_taxonomy.txt  # dada2_use_case.tsv

# Delimeter used in the OTU table file 
otu_table_delim: \t

# Taxonomy. 
# Set it to "GTDB" in case you have used the GTDB for your bins.
# Set it to "qiime2" or "dada2" in case you have used one of those
# Set it to "any" in case none of the previous apply
# REMEMBER! In all cases, you need to provide a 7-level taxonomy as described in the "how to"
taxonomy: qiime2  # dada2

# Column name denoting the OTU id; if special characters, for example "#", use double quotes 
otu_identifier_column: "#OTU ID"     # qiime2 -> "#OTU ID" dada2 -> "ASV_id"

# Column name denoting the taxonomy assignment of the OTU 
taxonomy_column_name : taxonomy

# Delimeter in the taxonomy column 
taxonomy_delimeter: ";"

# Character denoting commented lines if any in the OTU table
comments_character: "#"

# [ATTENTION! dada2 and qiim2 tests highlight difference] Column names are in the last comment line prior to any
column_names_are_in  : True # dada2 -> False   qiime2 -> True

# EDGE LIST
# ---------

# If co-occurrence network already available, please provide its edge list; a 2 column tab separated file
edge_list: 

# METADATA 
# --------
metadata_file:


# STEPS 
# --------

BugBase: False

PhenDB: False

FAPROTAX: False

NetCooperate: True

pathway_complementarity: 
    - skip_it: 
      default: False
    # - mode_for_species: 
    #   default: union

    # - mode_for_strain: 
    #   default: intersection


# ------
# TOOLS
# ------

# Flashweave
flashweave_opt:

  # Else, microbetag will invoke flashweave to build a co-occurrence network; fill in its paratemeters
  # If edge_list is not empty, please skip this section
  algorithmic_parameters:

    --heterogeneous:                            # enable heterogeneous mode for multi-habitat or -protocol data 
                                                # with at least thousands of samples (FlashWeaveHE)
    --sensitive:                                # enable fine-grained associations (FlashWeave-S, FlashWeaveHE-S), 
                                                # sensitive=false results in the fast modes FlashWeave-F or FlashWeaveHE-F
    --max_k:                                    # maximum size of conditioning sets, high values can strongly increase 
                                                # runtime. max_k=0 results in no conditioning (univariate mode)
    --alpha:                                    # threshold used to determine statistical significance

    --conv:                                     # convergence threshold, i.e. if conv=0.01 assume convergence 
                                                # if the number of edges increased by only 1% after 100% more runtime (checked in intervals)
    --feed_forward:                             # enable feed-forward heuristic

    --max_tests:                                # maximum number of conditional tests that should be performed on a variable pair 
                                                # before association is assumed

    --hps:                                      # reliability criterion for statistical tests when sensitive=false

    --FDR:                                      # perform False Discovery Rate correction (Benjamini-Hochberg method) 
                                                # on pairwise associations
    --n_obs_min:                                # don't compute associations between variables having less reliable samples 
                                                # (i.e. non-zero if heterogeneous=true) than this number. 
                                                # -1: automatically choose a threshold.
    --time_limit:                               # if feed-forward heuristic is active, determines the interval (seconds) 
                                                # at which neighborhood information is updated

  general_parameters:
    --normalize:                     # automatically choose and perform data normalization (based on sensitive and heterogeneous)
    --track_rejections:              # store for each discarded edge, which variable set  lead to its exclusion (can be memory intense for large networks)
    --verbose:                       # print progress information
    --transposed:                    # if true, rows of data are variables and columns are samples
    --prec:                          # precision in bits to use for calculations (16, 32, 64 or 128)
    --make_sparse:                   # use a sparse data representation (should be left at true in almost all cases)



# FAPROTAX optional parameters
faprotax_opt: 
  --force: False


# BugBase optional parameters
bugbase_opt:
  
  -c: taxonomy        # Map column header to plot by (which column denotes treatment groups)
  -w:           # Data is shotgun metagenomic data (picked against IMG database)
  -a:           # Plot all samples (no stats will be run)
  -x:           # Output prediction files only, no plots will be made
  -g:           # Specify subset of groups in map column to plot (list, comma separated)
  -z:           # Data is of type continuous 
  -C:           # Use coefficient of variance instead of variance to determine thresholds
  -l:           # Centered log-ratio transform the data instead of using relative abundance
  -t: 3           # Taxa level to plot OTU contributions by (number 1-7)
  -T:           # Specify a threshold to use for all traits (number 0-1)
  -k:           # Use the KEGG modules instead of default traits (Note: you must specify which modules!)
  -p:           # List modules or traits to predict (comma separated list, no spaces)
  -u:           # Use a user-define trait table. Absolute file path must be specified
  -m:         # give mapping file, example file under the tests/ folder


# microbetag needs to link the species level taxonomy assignments 
# to a NCBI Taxonomy id. If Silva is the reference taxonomy database used to get the OTU table, 
# then microbetag will do that automatically. 
# In case silva_db is False, the user needs to have an extra column 
# on the OTU table with the NCBI taxonomy id of the species found.
# Assignmnets that are not at the species level should filled with "null".
silva_db: True
